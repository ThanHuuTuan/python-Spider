# 爬取我主良缘网用户信息并可视化
我本可以忍受黑暗<br>
如果我不曾见过太阳

### 技术点：
- [x] 动态加载网站：json数据提取
- [x] 如何将图片批量保存在本地
- [x] 数据可视化
#### json数据提取
网站属于下拉动态加载网站，第一种也是最简单的方法就是通过分析AJAX来获取json数据。而我们也很迅速的就可以找到接口和数据，如何判断是否正确的获取到了数据：
```python
data = {
    'gender': '2',
    'marry':'1',
    'page':'1'
}
data['page']=i
url='http://www.lovewzly.com/api/user/pc/list/search?'
resp=requests.get(url,headers=headers,params=data)
if resp.status_code==200:
    data_json=resp.json()['data']['list']
```
一是基础太薄弱了，之前遇到国很多类似的网站，但是今日得到了反馈200却以为是上传数据的问题。200不就是对的反馈吗？之后就是json文件处理的问题，如何处理和提取json文件本来就是一件很简单的事情，但是不熟练导致了现在这样的情况时有发生。写一个部分总是需要借鉴之前的代码，这样的话确实就是个搬运工。<br>
关键词：<b>data_json=resp.json()</b>
 
 #### 如何批量保存图片到本地
 一开始以为是解析到了图片的url之后将图片保存在本地仍然是不可得，百度了许多文章，[为什么python3写的爬虫爬取到的图片无法打开？](https://segmentfault.com/q/1010000011782180)。参看了这篇博客之后才发现两个函数的url混淆在了一起刚好就发生了本文的问题。
```python
folder_path='./Photo'
if os.path.exists(folder_path)==False:
    os.makedirs(folder_path)
res=requests.get(url,headerh=headers)
# print(res)
# if url[0:5]=='http:':
#     img_url=url
# filename=url.split('/')[-1]
try:
    if 'png' in url:
        # print(url)
        fp = open('photo\\' +username+'.png', 'wb')
    else:
        fp = open('photo\\' + username + '.JPG', 'wb')
        # print(url)
    fp.write(res.content)
    print("Sucessful"+username)
    fp.close()
except:
    print("Failed"+username)
    pass
 ```
参考了许许多多的文章，有三个小的技术点：
- 创建文件夹:有了这个函数之后我们之后创建文件夹只需要调用该函数即可重新封装下
- 选择性提取图片文件名：使用切片的方法来判断图片的链接是否符合要求，并按照规定来提取链接的名称
- 判断图片链接类型：是png还是jpg

#### 数据可视化
主要涉及两个库：知道了如何从excle读取数据之后下一步就是如何从数据库读取数据，当然了之后只要是小项目都是可以从excle读取数据进行可视化，而这样的话也就可以做成动态的可视化页面了。之后再是数据库的数据可视化过程和web的配合。本文的教材确实是比较不错的了，可能是之前没有认真的学习别的教程，以至于看了本文档之后有点惊喜。从此入门了数据可视乎的大门，不至于什么都是静态的可视化。
- pandas:读取csv\excle文件的数据进行数据分析
```python
import pandas as pd
raw_data = pd.read_excel('我主良缘.xls',header=0,skiprows=0)
```
上面这个函数有很多的参数，首先是io的路径，然后是表的位置，我们都选默认的第一个表，然后是从第几行第几列到什么地方，我们这里都是默认的选择，主要目的是将整个表格的数据读取出来使用而已。
- pyecharts：利用pandas读取之后的数据进行数据可视化并保存在html页面上<br>
###### 身高分布柱状图：
![身高分布柱状图](https://github.com/afrunk/Summer-for-Learing/blob/master/Spider/Six--WZLY/1.PNG)
```python
from  pyecharts  import Bar
height_interval = ['140cm', '150cm', '160cm', '170cm', '180cm']

def analysis_height(data):
    height_data=data['height']#从excle里面读取到height这个属性的所有数据
    height = (height_data.loc[(height_data > 140) & (height_data < 200)]).value_counts().sort_index()
    #loc是pandas规范读取数据的一个方法，value_counts是统计整个身高有多少个元素的方法，最后是排序方法。
    height_count = [0, 0, 0, 0, 0]
    for h in range(0, len(height)):
        if 140 <= height.index[h] < 150:
            height_count[0] += height.values[h]
        elif 150 <= height.index[h] < 160:
            height_count[1] += height.values[h]
        elif 160 <= height.index[h] < 170:
            height_count[2] += height.values[h]
        elif 170 <= height.index[h] < 180:
            height_count[3] += height.values[h]
        elif 180 <= height.index[h] < 190:
            height_count[4] += height.values[h]
    print(height_count)
    ＃通过if-else来进行一个统计，返回一个列表，而这个列表就是pyechart需要的一个列表。
    return height_count


def draw_height_bar(data):
    bar = Bar("妹子身高分布柱状图")
    ＃Bar是导入的模块确定的
    bar.use_theme('dark')
    ＃这个是更改主题
    bar.add("妹子身高", height_interval, data, bar_category_gap=0, is_random=True, )
    ＃add()是主要方法，用于添加图表的数据和设置各项配置项
    ＃第一个参数是图表名字 第二个是横向的各项参数的名字，第三个是纵向的参数的值，第四个是是否添加如下载图片到本地，如果要提供更多使用工具，将is_more_utils设置为true即可。
    bar.render()
    ＃render()默认会在根目录下生成一个render.html的文件，支持path参数，设置文件保存位置，如render(r"e:\my_first_chart.html")
    ＃开始的时候不太明白两个函数的data是一样，那么怎么区别开来呢？后面才发现调用的时候是嵌套调用的，这样的话就没有任何区别的问题所在了，就是传递的是什么就是什么。
draw_height_bar(analysis_height(raw_data))
```
###### 身高分布圆环图
![图](https://github.com/afrunk/Summer-for-Learing/blob/master/Spider/Six--WZLY/0.PNG)
```python

# 绘制身高分布饼图
from pyecharts import Pie
def draw_height_pie(data):
    pie = Pie("妹子身高分布饼图-圆环图",title_pos='center')
    pie.add("", height_interval, data, radius=[40, 75], label_text_color=None,
        is_label_show=True, legend_orient='vertical',is_random=True,
        legend_pos='left')
    pie.render()
    return pie
draw_height_pie(analysis_height(raw_data))
```
###### 学历分布漏斗图
![图](https://github.com/afrunk/Summer-for-Learing/blob/master/Spider/Six--WZLY/2.PNG)
```python

edu_interval = ['本科', '大专', '高中', '中专', '初中', '硕士', '博士', '院士']  # 学历范围

# 分析学历
def analysis_edu(data):
    print(data['education'].value_counts().values)
    return data['education'].value_counts().values
# 学历漏斗图
def draw_edu_funnel(data):
    funnel = Funnel("妹子学历分布漏斗图",title_top='center')
    funnel.add("学历", edu_interval, data, is_label_show=True,label_pos="inside", label_text_color="#fff",is_random=True )
    funnel.render()
    return funnel

draw_edu_funnel(analysis_edu(raw_data))
```
###### 年龄雷达图
![图](https://github.com/afrunk/Summer-for-Learing/blob/master/Spider/Six--WZLY/4.PNG)
```python
age_interval = [
    ('18-25', 8000), ('26-30', 8000), ('31-40', 8000),
    ('41-50', 8000), ('50以上', 8000),
]

# 分析年龄
def analysis_age(data):
    age_data = data['birthdayyear']
    age = (age_data.loc[(age_data >= 1956) & (age_data <= 2000)]).value_counts().sort_index()
    age_count = [0, 0, 0, 0, 0]
    for h in range(0, len(age)):
        if 1993 <= age.index[h] <= 2000:
            age_count[0] += age.values[h]
        elif 1988 <= age.index[h] <= 1992:
            age_count[1] += age.values[h]
        elif 1978 <= age.index[h] <= 1987:
            age_count[2] += age.values[h]
        elif 1968 <= age.index[h] <= 1977:
            age_count[3] += age.values[h]
        elif age.index[h] < 1968:
            age_count[4] += age.values[h]
    print(age_count)
    return age_count

# 年龄雷达图
def draw_age_radar(data):
    radar = Radar("妹子年龄分布雷达图")
    radar.config(age_interval)
    radar.add("年龄段", data, is_area_show=False,legend_selectedmode='single')
    radar.render()
    # return radar
```
###### 要求词云
![图](https://github.com/afrunk/Summer-for-Learing/blob/master/Spider/Six--WZLY/3.PNG)
```python
from pyecharts import WordCloud
import re
import jieba as jb
from collections import Counter


# 过滤标点符号正则
word_pattern = re.compile('[\s+\.\!\/_,$%^*(+\"\']+|[+——！，。？“”、~@#￥%……&*（）(\d+)]+')
# 过滤无用词
exclude_words = [
            '一辈子', '不相离', '另一半', '业余时间', '性格特点', '茫茫人海', '男朋友', '找对象',
            '谈恋爱', '有时候', '女孩子', '哈哈哈', '加微信', '兴趣爱好',
            '是因为', '不良嗜好', '男孩子', '为什么', '没关系', '不介意',
            '没什么', '交朋友', '大大咧咧', '大富大贵', '联系方式', '打招呼',
            '有意者', '晚一点', '哈哈哈', '以上学历', '是不是', '给我发',
            '不怎么', '第一次', '越来越', '遇一人', '择一人', '无数次',
            '符合条件', '什么样', '全世界', '比较简单', '浪费时间', '不知不觉',
            '有没有', '寻寻觅觅', '自我介绍', '请勿打扰', '差不多', '不在乎', '看起来',
            '一点点', '陪你到', '这么久', '看清楚', '身高体重', '比较慢', '比较忙',
            '多一点', '小女生', '土生土长', '发消息', '最合适'
        ]

# 词频分布
def analysis_word(data):
    word_data = data['monolog'].value_counts()
    word_list = []
    for word in range(0, len(word_data)):
        if word_data.values[word] == 1:
            word_list.append(word_data.index[word])
    return word_list

# 交友宣言词云
def draw_word_wc(name, count):
    wc = WordCloud(width=900, height=720)
    wc.add("", name, count, word_size_range=[20, 100], shape='diamond')
    # wc.render()
    return wc

word_result = word_pattern.sub("", ''.join(analysis_word(raw_data)))
# Jieba分词
words = [word for word in jb.cut(word_result, cut_all=False) if len(word) >= 3]
# 遍历过滤无用词
for i in range(0, len(words)):
    if words[i] in exclude_words:
        words[i] = None
filter_list = list(filter(lambda t: t is not None, words))
data = r' '.join(filter_list)
# 词频统计
c = Counter(filter_list)
word_name = []  # 词
word_count = []  # 词频
for word_freq in c.most_common(100):
    word, freq = word_freq
    word_name.append(word)
    word_count.append(freq)

print(word_name)
```
类似项目：
- [爱情公寓电影](https://itcodemonkey.com/article/7502.html)
- [本文](https://github.com/coder-pig/ReptileSomething/blob/master/code/analysis/WZLY.ipynb)
- [浅尝数据分析](https://juejin.im/post/5aa26196518825557e77fc7a)
- [再尝数据分析](https://juejin.im/post/5ab4d79cf265da239c7b4cf9)
